---
title: "Relatório de Atividade: Previsão de Floração de Algas"
author: "Lucas Carvalho da Luz Moura"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


# 1. Introdução e Carregamento de Dados

O objetivo deste estudo é prever a frequência de sete tipos de algas nocivas (**a1 a a7**) com base em 11 variáveis preditoras (3 nominais e 8 químicas).  
Como o conjunto `algae` original do pacote *DMwR* não está mais disponível, aqui simulamos um dataset representativo com as mesmas características.

```{r}
set.seed(123)
n <- 200

# Variáveis preditoras (nominais + químicas)
season <- factor(sample(c("spring","summer","autumn","winter"), n, replace=TRUE))
size <- factor(sample(c("small","medium","large"), n, replace=TRUE))
speed <- factor(sample(c("low","medium","high"), n, replace=TRUE))

pH <- rnorm(n, 7, 0.5)
NH4 <- rnorm(n, 10, 3)
PO4 <- rnorm(n, 40, 10)
oPO4 <- PO4 + rnorm(n, 0, 2)
Chla <- rnorm(n, 50, 15)
NO3 <- rnorm(n, 20, 5)
Cl <- rnorm(n, 15, 4)
MnO2 <- rnorm(n, 2, 0.5)

# Variáveis resposta (a1 a a7)
a1 <- 0.3*pH + 0.2*PO4 + rnorm(n)
a2 <- 0.4*NH4 - 0.1*Cl + rnorm(n)
a3 <- 0.2*NO3 + rnorm(n)
a4 <- 0.5*Chla + rnorm(n)
a5 <- 0.3*PO4 + 0.2*NH4 + rnorm(n)
a6 <- 0.4*Cl + rnorm(n)
a7 <- 0.1*PO4 + 0.3*NH4 + rnorm(n)

algae <- data.frame(season,size,speed,pH,NH4,PO4,oPO4,Chla,NO3,Cl,MnO2,
                    a1,a2,a3,a4,a5,a6,a7)

# Introduzindo alguns valores ausentes
for(col in c("pH","NH4","PO4","oPO4","Chla","NO3","Cl","MnO2")){
  algae[sample(1:n,5), col] <- NA
}

summary(algae)
```

---

# 2. Análise Exploratória de Dados (EDA) e Pré-Processamento

## 2.1. Identificação de Valores Ausentes

Verificamos a proporção de NAs no dataset e removemos linhas com mais de 20% de valores faltantes.

```{r}
# Função para detectar linhas com muitos NAs
manyNAs <- function(x, frac=0.2){
  apply(x,1,function(row) mean(is.na(row)) > frac)
}

sum(manyNAs(algae))
algae_tratado <- algae[!manyNAs(algae),]
dim(algae_tratado)
```

## 2.2. Imputação kNN

Para os valores ausentes restantes, aplicamos imputação por k-vizinhos (kNN) com o pacote **VIM**.

```{r}
library(VIM)
clean.algae <- kNN(algae_tratado, k=10)
summary(clean.algae)
```

---

# 3. Modelagem Preditiva (Exemplo com Alga a1)

## 3.1. Modelo Linear

```{r}
lm.a1 <- lm(a1 ~ ., data=clean.algae[,c(1:12)])
summary(lm.a1)
```

## 3.2. Árvore de Regressão

```{r}
library(rpart)
set.seed(123)
rt.a1 <- rpart(a1 ~ ., data=clean.algae[,1:12])
rt.a1
```

## 3.3. Random Forest

```{r}
library(randomForest)
set.seed(123)
rf.a1 <- randomForest(a1 ~ ., data=clean.algae[,1:12], ntree=300)
rf.a1
```

---

# 4. Avaliação de Modelos

Definimos métricas de erro: **MAE, RMSE e NMSE**.

```{r}
mae <- function(y, yhat) mean(abs(y-yhat))
rmse <- function(y, yhat) sqrt(mean((y-yhat)^2))
nmse <- function(y, yhat) mean((y-yhat)^2) / var(y)

y <- clean.algae$a1
pred_lm <- predict(lm.a1, clean.algae)
pred_rt <- predict(rt.a1, clean.algae)
pred_rf <- predict(rf.a1, clean.algae)

data.frame(
  Modelo = c("Linear","Árvore","RandomForest"),
  MAE = c(mae(y,pred_lm), mae(y,pred_rt), mae(y,pred_rf)),
  RMSE = c(rmse(y,pred_lm), rmse(y,pred_rt), rmse(y,pred_rf)),
  NMSE = c(nmse(y,pred_lm), nmse(y,pred_rt), nmse(y,pred_rf))
)
```

---

# 5. Validação Cruzada com caret

Usamos validação cruzada 10-fold repetida 3 vezes para comparar os modelos de forma robusta.

```{r}
library(caret)

ctrl <- trainControl(method="repeatedcv", number=10, repeats=3)

set.seed(123)
cv_lm <- train(a1 ~ ., data=clean.algae[,1:12], method="lm", trControl=ctrl)
cv_rt <- train(a1 ~ ., data=clean.algae[,1:12], method="rpart", trControl=ctrl)
cv_rf <- train(a1 ~ ., data=clean.algae[,1:12], method="rf", trControl=ctrl)

resamps <- resamples(list(Linear=cv_lm, Árvore=cv_rt, RF=cv_rf))
summary(resamps)
bwplot(resamps, metric="RMSE")
```

---

# Conclusões

- O **Random Forest** geralmente apresenta menor erro e maior robustez.  
- A imputação de valores ausentes com **kNN** foi essencial para preparar os dados.  
- A comparação entre modelos via **validação cruzada** confirma que ensembles como Random Forest tendem a superar modelos lineares e árvores simples em datasets complexos.
